{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1519a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdchem, AllChem, MACCSkeys\n",
    "\n",
    "from openbabel import pybel\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error, r2_score\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ede0ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayerSimple(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, node_dim)\n",
    "        )\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, edge_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr):\n",
    "        row, col = edge_index\n",
    "        node_feat = torch.cat([h[row], edge_attr], dim=1)\n",
    "        delta_h = self.node_mlp(node_feat)\n",
    "\n",
    "        edge_feat = torch.cat([h[row], h[col], edge_attr], dim=1)\n",
    "        delta_edge = self.edge_mlp(edge_feat)\n",
    "\n",
    "        h = h + torch.zeros_like(h).scatter_add(0, row.unsqueeze(1).expand_as(delta_h), delta_h)\n",
    "        edge_attr = edge_attr + delta_edge\n",
    "        \n",
    "        return h, edge_attr\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Parameter(torch.randn(1, dim))  \n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "        self.scale = dim ** -0.5\n",
    "\n",
    "    def forward(self, h):\n",
    "        K = self.k_proj(h)  \n",
    "        V = self.v_proj(h)  \n",
    "        Q = self.q\n",
    "\n",
    "        scores = (Q @ K.T) * self.scale  \n",
    "        attn = F.softmax(scores, dim=-1) \n",
    "        out = attn @ V  \n",
    "\n",
    "        return out  \n",
    "\n",
    "class GNNFingerprintSimple(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim=256, num_layers=6, out_dim=1024):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.egnn_layers = nn.ModuleList([\n",
    "            GNNLayerSimple(node_dim, edge_dim, hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "        \n",
    "        self.attn_pool = AttentionPooling(node_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        t = False\n",
    "        if isinstance(data, list):\n",
    "            for graph in data:\n",
    "                if graph.edge_index.shape[0] != 2:\n",
    "                    graph.edge_index = graph.edge_index.t()\n",
    "            data = Batch.from_data_list(data)\n",
    "            t = True\n",
    "        else:\n",
    "            if data.edge_index.shape[0] != 2:\n",
    "                data.edge_index = data.edge_index.t()\n",
    "\n",
    "        h, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        for layer in self.egnn_layers:\n",
    "            h, edge_attr = layer(h, edge_index, edge_attr)\n",
    "\n",
    "        if t:\n",
    "            batch_size = data.num_graphs\n",
    "            pooled = torch.stack([ \n",
    "                self.attn_pool(h[data.batch == i]) for i in range(batch_size)\n",
    "            ])\n",
    "            pooled = pooled.squeeze(1)\n",
    "        else:\n",
    "            pooled = self.attn_pool(h)\n",
    "        \n",
    "        return self.projection_head(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8a915ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_features(mol):\n",
    "    \"\"\"Extracts bond features, including distances and angles.\"\"\"\n",
    "    edges, distances = [], []\n",
    "    axes = {\"X\": np.array([1, 0, 0]), \"Y\": np.array([0, 1, 0]), \"Z\": np.array([0, 0, 1])}\n",
    "\n",
    "    conf = mol.GetConformer()\n",
    "\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        pos_i, pos_j = np.array(conf.GetAtomPosition(i)), np.array(conf.GetAtomPosition(j))\n",
    "        vector_ij, norm_vector_ij = pos_j - pos_i, np.linalg.norm(pos_j - pos_i)\n",
    "        \n",
    "        if norm_vector_ij == 0:\n",
    "            continue  # Avoid division by zero\n",
    "        \n",
    "        distances.append(norm_vector_ij)\n",
    "        angles = {f\"angle_{axis}\": np.degrees(np.arccos(np.clip(np.dot(vector_ij, axis_vec) / norm_vector_ij, -1.0, 1.0))) for axis, axis_vec in axes.items()}\n",
    "        \n",
    "        bond_order = {\n",
    "            rdchem.BondType.SINGLE: 0.33,\n",
    "            rdchem.BondType.DOUBLE: 0.66,\n",
    "            rdchem.BondType.TRIPLE: 1.0,\n",
    "            rdchem.BondType.AROMATIC: 0.5\n",
    "        }.get(bond.GetBondType(), 0)\n",
    "        \n",
    "        edges.append([i, j, bond_order, norm_vector_ij, angles[\"angle_X\"], angles[\"angle_Y\"], angles[\"angle_Z\"]])\n",
    "    \n",
    "    edges = np.array(edges)\n",
    "    edges[:, 4:] /= 180  # Normalize angles\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def add_conformer_to_mol(mol, df):\n",
    "    conf = Chem.Conformer(mol.GetNumAtoms())\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        conf.SetAtomPosition(i, (row['x'], row['y'], row['z']))\n",
    "    \n",
    "    mol.AddConformer(conf, assignId=True)\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1e0176c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/means_and_stds.json\") as f:\n",
    "    scaler = json.load(f)\n",
    "\n",
    "def normalize_df(df, scaler):\n",
    "    df[\"x\"] = (df[\"x\"] - scaler[\"x_mean\"]) / scaler[\"x_std\"]\n",
    "    df[\"y\"] = (df[\"y\"] - scaler[\"y_mean\"]) / scaler[\"y_std\"]\n",
    "    df[\"z\"] = (df[\"z\"] - scaler[\"z_mean\"]) / scaler[\"z_std\"]\n",
    "    return df\n",
    "\n",
    "def preprocess_df(df, positions):\n",
    "    \"\"\"Preprocesses atomic and positional data for a molecule.\"\"\"\n",
    "    \n",
    "    # Define atomic number mappings\n",
    "    atom_options = {6: \"C\", 7: \"N\", 8: \"O\", 9: \"F\"}\n",
    "    \n",
    "    # One-hot encoding for atomic numbers\n",
    "    for key, label in atom_options.items():\n",
    "        df[label] = (df[\"atomic_num\"] == key).astype(int)\n",
    "    df.drop(columns=[\"atomic_num\"], inplace=True)\n",
    "    \n",
    "    # Normalize features\n",
    "    features = {\"num_bonds\": 4, \"hybridization\": 4, \"aromatic\": 1, \"chirality\": 2, \"valence\": 4, \"in_ring\": 1}\n",
    "    for feature, val in features.items():\n",
    "        df[feature] = df[feature].clip(0, val) / val\n",
    "        \n",
    "    # Process positional data\n",
    "    positions = normalize_df(positions, scaler).reset_index()\n",
    "    positions_df = pd.DataFrame(positions, columns=[\"x\", \"y\", \"z\"])\n",
    "    df = df.join(positions_df)\n",
    "    \n",
    "    return df, positions_df\n",
    "\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"Extracts atomic features from an RDKit atom object.\"\"\"\n",
    "    return {\n",
    "        \"atomic_num\": atom.GetAtomicNum(),\n",
    "        \"num_bonds\": len(atom.GetBonds()),\n",
    "        \"hybridization\": int(atom.GetHybridization()),\n",
    "        \"aromatic\": int(atom.GetIsAromatic()),\n",
    "        \"chirality\": int(atom.GetChiralTag()),\n",
    "        \"valence\": atom.GetTotalValence(),\n",
    "        \"in_ring\": int(atom.IsInRing()),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4520eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atoms_coordinates(smiles):\n",
    "    mol = pybel.readstring(\"smiles\", smiles)\n",
    "    mol.make3D()\n",
    "\n",
    "    atom_coordinates = []\n",
    "    for atom in mol.atoms:\n",
    "        atom_symbol = atom.type[0]  \n",
    "        atom_coords = atom.coords\n",
    "        atom_coordinates.append([atom_symbol, atom_coords[0], atom_coords[1], atom_coords[2]])\n",
    "\n",
    "    return atom_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "114e7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def craete_pos_df(atoms):\n",
    "    arr = []\n",
    "    for i,atom in enumerate(atoms):\n",
    "        if atom[0] != \"H\":\n",
    "            res = {}\n",
    "            res[\"x\"] = atom[1]\n",
    "            res[\"y\"] = atom[2]\n",
    "            res[\"z\"] = atom[3]\n",
    "            arr.append(res)\n",
    "    return pd.DataFrame(arr)\n",
    "\n",
    "def create_df_from_mol(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    atoms = get_atoms_coordinates(smiles)\n",
    "    node_features = [get_atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    atoms = craete_pos_df(atoms)\n",
    "    nodes, positions = preprocess_df(pd.DataFrame(node_features), atoms)\n",
    "    mol = add_conformer_to_mol(mol, positions)\n",
    "    edges = get_edge_features(mol)\n",
    "    return  mol, nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "67f20db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(nodes, edges):\n",
    "    x = torch.tensor(nodes.to_numpy(), dtype=torch.float).cuda()\n",
    "\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for edge in edges:\n",
    "        edge_index.append([edge[0], edge[1]])\n",
    "        edge_index.append([edge[1], edge[0]])\n",
    "\n",
    "        edge_attr.append(edge[2:])\n",
    "        edge_attr.append(edge[2:])\n",
    "        \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).cuda()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).cuda()\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "367f851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_27184\\3388430064.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  final_model.load_state_dict(torch.load('models/FINAL_GNN_NE_SMALLER.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNNFingerprintSimple(\n",
       "  (egnn_layers): ModuleList(\n",
       "    (0-5): 6 x GNNLayerSimple(\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=18, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=512, out_features=13, bias=True)\n",
       "      )\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=31, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projection_head): Sequential(\n",
       "    (0): Linear(in_features=13, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  )\n",
       "  (attn_pool): AttentionPooling(\n",
       "    (k_proj): Linear(in_features=13, out_features=13, bias=True)\n",
       "    (v_proj): Linear(in_features=13, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = GNNFingerprintSimple(13, 5, 256)\n",
    "final_model.load_state_dict(torch.load('models/FINAL_GNN_NE_SMALLER.pth'))\n",
    "final_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "801faa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_split_data_r(df, ki_threshold=1000):\n",
    "    df = df.copy()\n",
    "    df = df[df['Standard Value'] < ki_threshold]\n",
    "    df = df[['Smiles', 'Standard Value']].dropna()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['Smiles'], df['Standard Value'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train.reset_index(drop=True), X_test.reset_index(drop=True), y_train.reset_index(drop=True), y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2b6c38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_split_data_c(df, ki_threshold=1000):\n",
    "    df = df.copy()\n",
    "    df['Activity'] = df['Standard Value'].apply(lambda x: 1 if x < ki_threshold else 0)\n",
    "\n",
    "    df = df[['Smiles', 'Activity']].dropna()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['Smiles'], df['Activity'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train.reset_index(drop=True), X_test.reset_index(drop=True), y_train.reset_index(drop=True), y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "534d4a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_ecfp(smiles, radius=2, nbits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(nbits)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nbits)\n",
    "    arr = np.zeros((1,))\n",
    "    AllChem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "428711b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_maccs(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(167)\n",
    "    fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "    arr = np.zeros((167,), dtype=int)\n",
    "    Chem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e5837e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_rdkit_fp(smiles, nbits=2048):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(nbits)\n",
    "    fp = Chem.RDKFingerprint(mol, fpSize=nbits)\n",
    "    arr = np.zeros((nbits,), dtype=int)\n",
    "    Chem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d2e4abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprint_3d(smiles, model):\n",
    "    _, nodes, edges = create_df_from_mol(smiles)\n",
    "    record = read_graph(nodes, edges).to(\"cuda\")\n",
    "\n",
    "    return model(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "42f9b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"data\\CHEMBL\\CHEMBL224_5HT2A.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "33b1b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = filter_and_split_data_r(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "adb33e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(X_train, y_train, X_test, y_test, task=\"c\"):\n",
    "    s_scaler = StandardScaler()\n",
    "    X_train = s_scaler.fit_transform(X_train)\n",
    "    X_test = s_scaler.transform(X_test)\n",
    "\n",
    "    if task == \"c\":\n",
    "        model = LogisticRegression(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(\"Regression Metrics:\")\n",
    "        print(f\"MAE:  {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "        print(f\"R²:   {r2_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bcca6c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_27184\\4101620335.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fingerprint_model.load_state_dict(torch.load(r\"models\\FINAL_GNN_NE_SMALLER.pth\"))\n"
     ]
    }
   ],
   "source": [
    "X_train_ecfp = np.array([smiles_to_ecfp(smiles) for smiles in X_train])\n",
    "X_test_ecfp = np.array([smiles_to_ecfp(smiles) for smiles in X_test])\n",
    "\n",
    "X_train_maccs = np.array([smiles_to_maccs(smiles) for smiles in X_train])\n",
    "X_test_maccs = np.array([smiles_to_maccs(smiles) for smiles in X_test])\n",
    "\n",
    "X_train_rdk = np.array([smiles_to_rdkit_fp(smiles) for smiles in X_train])\n",
    "X_test_rdk = np.array([smiles_to_rdkit_fp(smiles) for smiles in X_test])\n",
    "\n",
    "#### 3D FINGERPRINT ####\n",
    "fingerprint_model = GNNFingerprintSimple(13, 5, 256)\n",
    "fingerprint_model.load_state_dict(torch.load(r\"models\\FINAL_GNN_NE_SMALLER.pth\"))\n",
    "fingerprint_model = fingerprint_model.to(\"cuda\")\n",
    "fingerprint_model.eval()\n",
    "\n",
    "X_train_3D = np.array([fingerprint_3d(smiles, fingerprint_model).detach().cpu() for smiles in X_train]).squeeze(1)\n",
    "X_test_3D = np.array([fingerprint_3d(smiles, fingerprint_model).detach().cpu() for smiles in X_test]).squeeze(1)\n",
    "\n",
    "rows_all_nan_train = np.isnan(X_train_3D).all(axis=1)\n",
    "nan_indices_train = np.where(rows_all_nan_train)[0]\n",
    "\n",
    "rows_all_nan_test = np.isnan(X_test_3D).all(axis=1)\n",
    "nan_indices_test = np.where(rows_all_nan_test)[0]\n",
    "\n",
    "X_train_3D = np.delete(X_train_3D, nan_indices_train, axis=0)\n",
    "y_train_3D = np.delete(y_train, nan_indices_train, axis=0)\n",
    "X_test_3D = np.delete(X_test_3D, nan_indices_test, axis=0)\n",
    "y_test_3D = np.delete(y_test, nan_indices_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2205e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ECFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "42f6659e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics:\n",
      "MAE:  141.6878\n",
      "R²:   0.1061\n"
     ]
    }
   ],
   "source": [
    "get_score(X_train_ecfp, y_train, X_test_ecfp, y_test, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4e19b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MACCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "870ea1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics:\n",
      "MAE:  133.0207\n",
      "R²:   0.2341\n"
     ]
    }
   ],
   "source": [
    "get_score(X_train_maccs, y_train, X_test_maccs, y_test, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0f6e68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##RDKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "69d32afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics:\n",
      "MAE:  288.3204\n",
      "R²:   -4.6206\n"
     ]
    }
   ],
   "source": [
    "get_score(X_train_rdk, y_train, X_test_rdk, y_test, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "327391b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a5fbc96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics:\n",
      "MAE:  153.9368\n",
      "R²:   0.0472\n"
     ]
    }
   ],
   "source": [
    "get_score(X_train_3D, y_train_3D, X_test_3D, y_test_3D, \"r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldd25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
